# -*- coding: utf-8 -*-
"""ML_Project1_ModelSelection.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1Y0FIC0jthwdfXY1_OUkE7q23XUTrh8Ux
"""

import pandas as pd
from google.colab import files

# Upload file
uploaded = files.upload()

# Get the actual filename from the uploaded dictionary
filename = list(uploaded.keys())[0]  # Assuming only one file was uploaded

# Load dataset using the correct filename
df = pd.read_csv(filename)
df.head()  # Display first few rows of the dataset

import pandas as pd
from sklearn.model_selection import train_test_split
from sklearn.preprocessing import StandardScaler, LabelEncoder
from sklearn.impute import SimpleImputer

# 1. Load the data
df = pd.read_csv('diabetes_50000 (1).csv')

# 2. Handle missing values (using mean imputation)
imputer = SimpleImputer(strategy='mean')
df_imputed = pd.DataFrame(imputer.fit_transform(df), columns=df.columns)

# 3. Check for categorical columns (if any) and encode them (assuming 'categorical_column' is one of them)
categorical_columns = df_imputed.select_dtypes(include=['object']).columns
if len(categorical_columns) > 0:
    for col in categorical_columns:
        df_imputed[col] = LabelEncoder().fit_transform(df_imputed[col])

# Assuming 'label' is the column name for the target
X = df_imputed.drop('Has_diabetes', axis=1)  # Drop the target column to get features
y = df_imputed['Has_diabetes']  # The target column

# 5. Split data into training and testing sets
X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)

# Output the shapes of the training and test sets
print(f"Training set shape: {X_train.shape}")
print(f"Test set shape: {X_test.shape}")

from sklearn.tree import DecisionTreeClassifier
from sklearn.ensemble import RandomForestClassifier
from sklearn.metrics import accuracy_score
from sklearn.model_selection import cross_val_score

# Initialize classifiers
dt_classifier = DecisionTreeClassifier(random_state=42)
rf_classifier = RandomForestClassifier(random_state=42)

# Train models
dt_classifier.fit(X_train, y_train)
rf_classifier.fit(X_train, y_train)

# Evaluate models
dt_predictions = dt_classifier.predict(X_test)
rf_predictions = rf_classifier.predict(X_test)

# Calculate accuracy using cross-validation to get mean and standard deviation
# Change cv to desired number of folds
dt_scores = cross_val_score(dt_classifier, X, y, cv=5, scoring='accuracy')
rf_scores = cross_val_score(rf_classifier, X, y, cv=5, scoring='accuracy')

# Calculate mean and standard deviation of accuracy scores
dt_mean = dt_scores.mean()
dt_std = dt_scores.std()
rf_mean = rf_scores.mean()
rf_std = rf_scores.std()

# Print results
print("Decision Tree Accuracy - Mean:", dt_mean, "Standard Deviation:", dt_std)
print("Random Forest Accuracy - Mean:", rf_mean, "Standard Deviation:", rf_std)

from sklearn.model_selection import GridSearchCV

# Set up the parameter grid for both classifiers
param_grid_dt = {'max_depth': [3, 5, 10], 'min_samples_split': [2, 5, 10]}
param_grid_rf = {'n_estimators': [50, 100, 200], 'max_depth': [5, 10, 15]}

# Grid Search with Cross Validation for DecisionTree
grid_search_dt = GridSearchCV(dt_classifier, param_grid_dt, cv=5)
grid_search_dt.fit(X_train, y_train)
print("Best Decision Tree parameters:", grid_search_dt.best_params_)

# Grid Search with Cross Validation for RandomForest
grid_search_rf = GridSearchCV(rf_classifier, param_grid_rf, cv=5)
grid_search_rf.fit(X_train, y_train)
print("Best Random Forest parameters:", grid_search_rf.best_params_)

import pickle

# Save the model
best_model = grid_search_rf.best_estimator_  # Choose the best model
with open('best_model.pkl', 'wb') as file:
    pickle.dump(best_model, file)

# Load the model
with open('best_model.pkl', 'rb') as file:
    loaded_model = pickle.load(file)

# Predict using the saved model
predictions = loaded_model.predict(X_test)
accuracy = accuracy_score(y_test, predictions)
print(f"Accuracy of the best model: {accuracy}")

# Additional analysis (mean, standard deviation)
from sklearn.model_selection import cross_val_score

scores = cross_val_score(loaded_model, X_train, y_train, cv=5)
print(f"Mean CV Score: {scores.mean()}")
print(f"Standard Deviation of CV Score: {scores.std()}")